{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Moore assignment_kaggle_challenge_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HadenMoore/DS-Unit-2-Kaggle-Challenge/blob/master/Moore_assignment_kaggle_challenge_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IXUfiQ2UKj6",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Kaggle Challenge, Module 2\n",
        "\n",
        "## Assignment\n",
        "- [ ] Read [“Adopting a Hypothesis-Driven Workflow”](https://outline.com/5S5tsB), a blog post by a Lambda DS student about the Tanzania Waterpumps challenge.\n",
        "- [ ] Continue to participate in our Kaggle challenge.\n",
        "- [ ] Try Ordinal Encoding.\n",
        "- [ ] Try a Random Forest Classifier.\n",
        "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "### Doing\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Do more exploratory data analysis, data cleaning, feature engineering, and feature selection.\n",
        "- [ ] Try other [categorical encodings](https://contrib.scikit-learn.org/categorical-encoding/).\n",
        "- [ ] Get and plot your feature importances.\n",
        "- [ ] Make visualizations and share on Slack.\n",
        "\n",
        "### Reading\n",
        "\n",
        "Top recommendations in _**bold italic:**_\n",
        "\n",
        "#### Decision Trees\n",
        "- A Visual Introduction to Machine Learning, [Part 1: A Decision Tree](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/),  and _**[Part 2: Bias and Variance](http://www.r2d3.us/visual-intro-to-machine-learning-part-2/)**_\n",
        "- [Decision Trees: Advantages & Disadvantages](https://christophm.github.io/interpretable-ml-book/tree.html#advantages-2)\n",
        "- [How a Russian mathematician constructed a decision tree — by hand — to solve a medical problem](http://fastml.com/how-a-russian-mathematician-constructed-a-decision-tree-by-hand-to-solve-a-medical-problem/)\n",
        "- [How decision trees work](https://brohrer.github.io/how_decision_trees_work.html)\n",
        "- [Let’s Write a Decision Tree Classifier from Scratch](https://www.youtube.com/watch?v=LDRbO9a6XPU)\n",
        "\n",
        "#### Random Forests\n",
        "- [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/), Chapter 8: Tree-Based Methods\n",
        "- [Coloring with Random Forests](http://structuringtheunstructured.blogspot.com/2017/11/coloring-with-random-forests.html)\n",
        "- _**[Random Forests for Complete Beginners: The definitive guide to Random Forests and Decision Trees](https://victorzhou.com/blog/intro-to-random-forests/)**_\n",
        "\n",
        "#### Categorical encoding for trees\n",
        "- [Are categorical variables getting lost in your random forests?](https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/)\n",
        "- [Beyond One-Hot: An Exploration of Categorical Variables](http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/)\n",
        "- _**[Categorical Features and Encoding in Decision Trees](https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931)**_\n",
        "- _**[Coursera — How to Win a Data Science Competition: Learn from Top Kagglers — Concept of mean encoding](https://www.coursera.org/lecture/competitive-data-science/concept-of-mean-encoding-b5Gxv)**_\n",
        "- [Mean (likelihood) encodings: a comprehensive study](https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study)\n",
        "- [The Mechanics of Machine Learning, Chapter 6: Categorically Speaking](https://mlbook.explained.ai/catvars.html)\n",
        "\n",
        "#### Imposter Syndrome\n",
        "- [Effort Shock and Reward Shock (How The Karate Kid Ruined The Modern World)](http://www.tempobook.com/2014/07/09/effort-shock-and-reward-shock/)\n",
        "- [How to manage impostor syndrome in data science](https://towardsdatascience.com/how-to-manage-impostor-syndrome-in-data-science-ad814809f068)\n",
        "- [\"I am not a real data scientist\"](https://brohrer.github.io/imposter_syndrome.html)\n",
        "- _**[Imposter Syndrome in Data Science](https://caitlinhudon.com/2018/01/19/imposter-syndrome-in-data-science/)**_\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9eSnDYhUGD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you're in Colab...\n",
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "if in_colab:\n",
        "    # Install required python packages:\n",
        "    # category_encoders, version >= 2.0\n",
        "    # pandas-profiling, version >= 2.0\n",
        "    # plotly, version >= 4.0\n",
        "    !pip install --upgrade category_encoders pandas-profiling plotly\n",
        "    \n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-LBYcZdzAzA",
        "colab_type": "text"
      },
      "source": [
        "# Import / Starting Point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJBD4ruICm1m",
        "colab_type": "code",
        "outputId": "0a030d87-d760-4cad-c796-6f81d5092e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv('../data/tanzania/train_features.csv'), \n",
        "                 pd.read_csv('../data/tanzania/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv('../data/tanzania/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
        "\n",
        "# Split train into train & val\n",
        "train, valdt = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "train.shape, valdt.shape, test.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((47520, 41), (11880, 41), (14358, 40))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LgqqYwi2G1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Possible imports\n",
        "\n",
        "%matplotlib inline\n",
        "import itertools\n",
        "from math import floor\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU9u8M6hwfyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv('../data/tanzania/train_features.csv'), \n",
        "                 pd.read_csv('../data/tanzania/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv('../data/tanzania/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
        "\n",
        "# Split train into train & val\n",
        "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    # Also create a \"missing indicator\" column, because the fact that\n",
        "    # values are missing may be a predictive signal.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "                       'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_MISSING'] = X[col].isnull()\n",
        "            \n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    X = X.drop(columns=duplicates)\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "    \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "    \n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    X['years'] = X['year_recorded'] - X['construction_year']\n",
        "    X['years_MISSING'] = X['years'].isnull()\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5Pslg2ayTwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The status_group column is the target\n",
        "target = 'status_group'\n",
        "\n",
        "# Get a dataframe with all train columns except the target\n",
        "train_features = train.drop(columns=[target])\n",
        "\n",
        "# Get a list of the numeric features\n",
        "numeric_features = train_features.select_dtypes(include='number').columns.tolist()\n",
        "\n",
        "# Get a series with the cardinality of the nonnumeric features\n",
        "cardinality = train_features.select_dtypes(exclude='number').nunique()\n",
        "\n",
        "# Get a list of all categorical features with cardinality <= 50\n",
        "categorical_features = cardinality[cardinality <= 50].index.tolist()\n",
        "\n",
        "# Combine the lists \n",
        "features = numeric_features + categorical_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q55YkPOlyYYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector \n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "X_test = test[features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf0F-CYXzr8p",
        "colab_type": "text"
      },
      "source": [
        "### Using Scikit-learn for Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_XmmspIy-A4",
        "colab_type": "code",
        "outputId": "d2cf71fc-0f99-4560-81a4-fa510b8d2b34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "%%time\n",
        "# WARNING: there are some quirks sometimes with this command,\n",
        "# can lead to weird bugs/behavior\n",
        "\n",
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names='True'), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8082491582491582\n",
            "CPU times: user 29.6 s, sys: 221 ms, total: 29.8 s\n",
            "Wall time: 18.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDlyIgxO2gL5",
        "colab_type": "text"
      },
      "source": [
        "# Some Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl1tGKZyzjXP",
        "colab_type": "code",
        "outputId": "90455e03-6007-4626-805d-6e4396da32f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        }
      },
      "source": [
        "train.isnull().sum()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "amount_tsh                       0\n",
              "funder                        2904\n",
              "gps_height                   16305\n",
              "installer                     2917\n",
              "longitude                     1442\n",
              "latitude                      1442\n",
              "wpt_name                         0\n",
              "num_private                      0\n",
              "basin                            0\n",
              "subvillage                     286\n",
              "region                           0\n",
              "region_code                      0\n",
              "district_code                    0\n",
              "lga                              0\n",
              "ward                             0\n",
              "population                   17066\n",
              "public_meeting                2644\n",
              "scheme_management             3128\n",
              "scheme_name                  22532\n",
              "permit                        2443\n",
              "construction_year            16517\n",
              "extraction_type                  0\n",
              "extraction_type_group            0\n",
              "extraction_type_class            0\n",
              "management                       0\n",
              "management_group                 0\n",
              "payment                          0\n",
              "water_quality                    0\n",
              "quality_group                    0\n",
              "quantity                         0\n",
              "source                           0\n",
              "source_type                      0\n",
              "source_class                     0\n",
              "waterpoint_type                  0\n",
              "waterpoint_type_group            0\n",
              "status_group                     0\n",
              "longitude_MISSING                0\n",
              "latitude_MISSING                 0\n",
              "construction_year_MISSING        0\n",
              "gps_height_MISSING               0\n",
              "population_MISSING               0\n",
              "year_recorded                    0\n",
              "month_recorded                   0\n",
              "day_recorded                     0\n",
              "years                        16517\n",
              "years_MISSING                    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DHCbYcR2kig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "high_ordinal = ['longitude', 'wpt_name', 'subvillage', 'scheme_name', 'installer', 'funder', \n",
        "    'lga']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5hbsOsS2nIt",
        "colab_type": "code",
        "outputId": "b8057fd1-c54c-4922-89c6-6df4ed5a80a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        }
      },
      "source": [
        "encoder = ce.OrdinalEncoder()\n",
        "encoded = encoder.fit_transform(train[high_ordinal])\n",
        "encoded.head(20)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>wpt_name</th>\n",
              "      <th>subvillage</th>\n",
              "      <th>scheme_name</th>\n",
              "      <th>installer</th>\n",
              "      <th>funder</th>\n",
              "      <th>lga</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43360</th>\n",
              "      <td>33.542898</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7263</th>\n",
              "      <td>34.665760</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2486</th>\n",
              "      <td>38.238568</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>30.716727</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52726</th>\n",
              "      <td>35.389331</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8558</th>\n",
              "      <td>31.214583</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2559</th>\n",
              "      <td>36.696700</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54735</th>\n",
              "      <td>36.292724</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25763</th>\n",
              "      <td>32.877248</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44540</th>\n",
              "      <td>33.014412</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28603</th>\n",
              "      <td>38.950769</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4372</th>\n",
              "      <td>39.020094</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30666</th>\n",
              "      <td>36.694357</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6431</th>\n",
              "      <td>38.890990</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57420</th>\n",
              "      <td>31.746292</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1373</th>\n",
              "      <td>37.501573</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2026</th>\n",
              "      <td>35.371400</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58977</th>\n",
              "      <td>38.018784</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41101</th>\n",
              "      <td>29.660968</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10019</th>\n",
              "      <td>35.714295</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       longitude  wpt_name  subvillage  scheme_name  installer  funder  lga\n",
              "43360  33.542898         1           1            1          1       1    1\n",
              "7263   34.665760         2           2            2          2       2    2\n",
              "2486   38.238568         3           3            3          3       3    3\n",
              "313    30.716727         4           4            3          4       4    4\n",
              "52726  35.389331         5           5            4          5       5    5\n",
              "8558   31.214583         6           6            5          4       6    6\n",
              "2559   36.696700         7           7            6          4       7    7\n",
              "54735  36.292724         8           8            7          4       5    8\n",
              "25763  32.877248         9           9            3          6       8    9\n",
              "44540  33.014412        10          10            3          7       9   10\n",
              "28603  38.950769        11          11            3          8      10   11\n",
              "4372   39.020094        12          12            8          4      11   12\n",
              "30666  36.694357         8          13            3          1       2   13\n",
              "6431   38.890990        13          14            9          9      12    3\n",
              "57420  31.746292        14           4            3          4      13   14\n",
              "1373   37.501573        15          15           10          4       4   15\n",
              "2026   35.371400        16          16           11         10      14   16\n",
              "58977  38.018784        17          17            3         11       4   17\n",
              "41101  29.660968        18          18           12         12      15   18\n",
              "10019  35.714295        19          19           13         13      16   19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKXnqOYJ2tHq",
        "colab_type": "code",
        "outputId": "4c6d9802-19ec-424a-f887-775f9a592764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        }
      },
      "source": [
        "# Inspect Data Types.\n",
        "train.dtypes"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "amount_tsh                   float64\n",
              "funder                        object\n",
              "gps_height                   float64\n",
              "installer                     object\n",
              "longitude                    float64\n",
              "latitude                     float64\n",
              "wpt_name                      object\n",
              "num_private                    int64\n",
              "basin                         object\n",
              "subvillage                    object\n",
              "region                        object\n",
              "region_code                    int64\n",
              "district_code                  int64\n",
              "lga                           object\n",
              "ward                          object\n",
              "population                   float64\n",
              "public_meeting                object\n",
              "scheme_management             object\n",
              "scheme_name                   object\n",
              "permit                        object\n",
              "construction_year            float64\n",
              "extraction_type               object\n",
              "extraction_type_group         object\n",
              "extraction_type_class         object\n",
              "management                    object\n",
              "management_group              object\n",
              "payment                       object\n",
              "water_quality                 object\n",
              "quality_group                 object\n",
              "quantity                      object\n",
              "source                        object\n",
              "source_type                   object\n",
              "source_class                  object\n",
              "waterpoint_type               object\n",
              "waterpoint_type_group         object\n",
              "status_group                  object\n",
              "longitude_MISSING               bool\n",
              "latitude_MISSING                bool\n",
              "construction_year_MISSING       bool\n",
              "gps_height_MISSING              bool\n",
              "population_MISSING              bool\n",
              "year_recorded                  int64\n",
              "month_recorded                 int64\n",
              "day_recorded                   int64\n",
              "years                        float64\n",
              "years_MISSING                   bool\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHDXVFVE31N4",
        "colab_type": "text"
      },
      "source": [
        "# Run in Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBthg6HF34Ah",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXMExPgO3yHq",
        "colab_type": "code",
        "outputId": "4daf1c21-5ace-4ad3-f518-62d4f1421a19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# With a pipline: LogisticRegression\n",
        "\n",
        "#one-hot / standard-scale / fit / score \n",
        "# (note: subset already dertermined ABOVE when defining X_train, etc. )\n",
        "\n",
        "pipe = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(),                          # also I'm using this, cause...\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1005)\n",
        "    )\n",
        "\n",
        "# fit model to train set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# score model on val set\n",
        "print('Validate that stuff:', pipe.score(X_val, y_val))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validate that stuff: 0.7366161616161616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uhqYvxw3-9y",
        "colab_type": "text"
      },
      "source": [
        "# Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT6qgUAO39Oh",
        "colab_type": "code",
        "outputId": "f5ce3803-ccac-4c20-b406-bb234be24164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " #With a pipline:   DecisionTreeClassifier\n",
        "\n",
        "pipe_dt = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    DecisionTreeClassifier(random_state=42, min_samples_leaf=20, max_depth=19)\n",
        "    )\n",
        "\n",
        "# fit model to train set\n",
        "pipe_dt.fit(X_train, y_train)\n",
        "\n",
        "# score model on val set\n",
        "print('Validate that Stuff:', pipe_dt.score(X_val, y_val))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validate that Stuff: 0.7681818181818182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfIPWgES4jRw",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5oycU-64FZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxujzy-H4ncf",
        "colab_type": "code",
        "outputId": "7fa2a68a-220f-4ae7-b6ab-2492b583a3a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "    )\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8106060606060606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd-RKvhP4x4W",
        "colab_type": "text"
      },
      "source": [
        "# Don't Experiment.. Jk Do it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koqUI1_O4rHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install dirty_cat\n",
        "# encoder = dirty_cat.TargetEncoder(clf_type='multiclass-clf')\n",
        "# ce.TargetEncoder(\n",
        "    from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U46ofZkE45jx",
        "colab_type": "code",
        "outputId": "e7a0c0cb-2667-48f5-db9d-ead86db053f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pipe_experiment = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'),\n",
        "    GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, \n",
        "                               max_depth=8, random_state=42)\n",
        "    )\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipe_experiment.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipe_experiment.score(X_val, y_val))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7792087542087542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADpx_zDj5Dd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(strategy='median'),\n",
        "    AdaBoostClassifier(\n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n",
        "    )\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOZaeCPQ5LaU",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2heuqFm75Nvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Last Step\n",
        "\n",
        "# Predict on test\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "\n",
        "# Write submission csv file\n",
        "submission = sample_submission.copy()\n",
        "submission['status_group'] = y_pred\n",
        "submission.to_csv('Haden_submit_2.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebwM2KO35YuV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "0a41d5c0-91f9-4015-de88-1ecfb431e1ae"
      },
      "source": [
        "!head Haden_submit_2.csv"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id,status_group\n",
            "50785,non functional\n",
            "51630,functional\n",
            "17168,functional\n",
            "45559,non functional\n",
            "49871,functional\n",
            "52449,functional\n",
            "24806,functional\n",
            "28965,non functional\n",
            "36301,non functional\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsFOWBWQ5cZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if in_colab:\n",
        "    from google.colab import files\n",
        "    # Just try again if you get this error:\n",
        "    # TypeError: Failed to fetch\n",
        "    # https://github.com/googlecolab/colabtools/issues/337\n",
        "    files.download('Haden_submit_2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}